Projet :  Analyse de Données Massives avec Spark 
Objectif 
Réalisation un mini-projet d’analyse de données massives en utilisant Apache Spark, en appliquant 
les notions étudiées : architecture Spark, RDD, DataFrames, transformations, actions et 
analyse exploratoire. 
Jeu de données 

Travail centre sur : 
Modélisation 
• Utilisation principale des DataFrames 
• Comparaison partielle avec les RDD 
• Justification des choix techniques (optimisation, performance, cas d’usage) 
Transformations et actions 
• 5 transformations (ex. : filter, select, groupBy, orderBy, withColumn) 
• 3 actions (ex. : count, show, write) 
Analyse du dataset 
• Formuler 3 à 4 questions métier 
• Produire des résultats concrets : statistiques, agrégations, top N, distributions 
• Appliquer un nettoyage de base si nécessaire : valeurs manquantes, types incorrects, 
incohérences 
